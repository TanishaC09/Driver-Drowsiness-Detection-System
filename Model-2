import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

##
import numpy as np
import pandas as pd
import os
import cv2

import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import layers

##
batch_size = 40
img_height = 256
img_width = 256

##
# loading training data
training_ds = tf.keras.preprocessing.image_dataset_from_directory(
    '/kaggle/input/yawn-eye-dataset-new/dataset_new/train',
    #validation_split=0.2,
    #subset= "training",
    seed=42,
    image_size= (img_height, img_width),
    batch_size=batch_size

)

# loading testing data
testing_ds = tf.keras.preprocessing.image_dataset_from_directory(
'/kaggle/input/yawn-eye-dataset-new/dataset_new/test',
    #validation_split=0.2,
    #subset= "validation",
    seed=42,
    image_size= (img_height, img_width),
    batch_size=batch_size

)


##
class_names = training_ds.class_names

##
for images, labels in training_ds.take(1):
  for i in range(2):
    print(images)

##
plt.figure(figsize=(10, 10))
for images, labels in training_ds.take(1):
  for i in range(12):
    ax = plt.subplot(3,4 , i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.grid(True)

## Configuring dataset for performance
AUTOTUNE = tf.data.experimental.AUTOTUNE
training_ds = training_ds.cache().prefetch(buffer_size=AUTOTUNE)
testing_ds = testing_ds.cache().prefetch(buffer_size=AUTOTUNE)

##
import tensorflow as tf
import numpy as np
import pandas as pd
import cv2
import os
from zipfile import ZipFile
from tqdm import tqdm
import matplotlib.pyplot as plt
from tensorflow.keras.utils import img_to_array
from keras.utils import np_utils
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from keras.models import Sequential
# Define the input shape of the network
input_shape = (None, 256, 256, 3)
model = tf.keras.models.Sequential([
        # Conv1(6,5,1) - A - Pool1(2 × 2)
        tf.keras.layers.Conv2D(filters=6, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=input_shape[1:]),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

        # Conv2(8,5,1) - A - Pool2(2 × 2)
        tf.keras.layers.Conv2D(filters=8, kernel_size=5, strides=1, padding='same', activation='relu'),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

        # Conv3(10,4,1) - A - Pool3
        tf.keras.layers.Conv2D(filters=10, kernel_size=4, strides=1, padding='same', activation='relu'),
        tf.keras.layers.BatchNormalization(),tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),

        # FullyCon1(128)
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(units=128, activation='relu'),

        # Output layer
        tf.keras.layers.Dense(units=4, activation='softmax')
    ])

##
model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])

##
retVal = model.fit(training_ds, validation_data= testing_ds, epochs = 30)

##
plt.plot(retVal.history['loss'], label = 'training loss')
plt.plot(retVal.history['accuracy'], label = 'training accuracy')
plt.grid(True)
plt.legend()

##
acc = retVal.history['accuracy']
loss = retVal.history['loss']

plt.figure(figsize = (8,8))
plt.subplot(1,2,1)
plt.plot(range(30),acc,label='Training Accuracy')
plt.legend(loc="lower right")
plt.title("Training over30 epochs")

##
model.save('drowsiness-stage3.h5')

##
plt.figure(figsize=(20, 20))
for images, labels in testing_ds.take(2):
    predictions = model.predict(images)
    predlabel = []

    for mem in predictions:
        predlabel.append(class_names[np.argmax(mem)])

    for i in range(40):
        ax = plt.subplot(10, 4, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))
        plt.title('Predicted label:'+ predlabel[i])
        plt.axis('off')
        plt.grid(True)

##
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Get the true labels and predicted labels
y_true = np.concatenate([y for x, y in testing_ds], axis=0)
y_pred = np.argmax(model.predict(testing_ds), axis=1)

# Get the class names
class_names = ['closed_eye', 'open_eye', 'yawning', 'no_yawn']

# Print accuracy score
accuracy = accuracy_score(y_true, y_pred)
print(f"Testing accuracy: {accuracy:.2%}")

# Print classification report
print(classification_report(y_true, y_pred, target_names=class_names))

# Print confusion matrix
cm = confusion_matrix(y_true, y_pred)
print('Confusion matrix:')
print(cm)
plt.figure(figsize=(6, 6))
plt.imshow(cm, cmap='Blues')
plt.title('Confusion Matrix')
plt.colorbar()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names, rotation=45)
plt.yticks(tick_marks, class_names)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

##



